{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# How do I use Riva TTS APIs with out-of-the-box models?\n",
    "\n",
    "This tutorial walks you through the basics of Riva Speech Skills's TTS Services, specifically covering how to use Riva TTS APIs with out-of-the-box models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NVIDIA Riva Overview\n",
    "\n",
    "NVIDIA Riva is a GPU-accelerated SDK for building Speech AI applications that are customized for your use case and deliver real-time performance. <br/>\n",
    "Riva offers a rich set of speech services such as:\n",
    "\n",
    "- Automated speech recognition (ASR)\n",
    "- Text-to-Speech synthesis (TTS)\n",
    "\n",
    "In this tutorial, we will interact with the text-to-speech synthesis (TTS) APIs.\n",
    "\n",
    "For more information about Riva, please refer to the [Riva developer documentation](https://developer.nvidia.com/riva)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech generation with Riva TTS APIs\n",
    "\n",
    "The Riva TTS service is based on a two-stage pipeline: Riva first generates a mel spectrogram using the first model, then generates speech using the second model. This pipeline forms a text-to-speech system that enables you to synthesize natural sounding speech from raw transcripts without any additional information such as patterns or rhythms of speech.\n",
    "\n",
    "Riva provides two state-of-the-art voices (one male and one female) for English, that can easily be deployed with the Riva Quick Start scripts. Riva also supports easy customization of TTS in various ways, to meet your specific needs.\n",
    "\n",
    "Subsequent Riva releases will include added features, including model registration to support multiple languages/voices with the same API. Support for resampling to alternative sampling rates will also be added.\n",
    "\n",
    "Refer to the [Riva TTS documentation](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/tts/tts-overview.html) for more information.  \n",
    "\n",
    "Now, let's generate audio using Riva APIs with an OOTB (out-of-the-box) English TTS pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Riva clent libraries\n",
    "\n",
    "We first import some required libraries, including the Riva client libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import grpc\n",
    "\n",
    "import riva.client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Riva clients and connect to Riva Speech API server\n",
    "\n",
    "The below URI assumes a local deployment of the Riva Speech API server on the default port. In case the server deployment is on a different host or via Helm chart on Kubernetes, the user should use an appropriate URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = riva.client.Auth(uri='localhost:50051')\n",
    "\n",
    "riva_tts = riva.client.SpeechSynthesisService(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch mode TTS\n",
    "\n",
    "Riva TTS supports both streaming and batch inference modes. In batch mode, audio is not returned until the full audio sequence for the requested text is generated and can achieve higher throughput. But when making a streaming request, audio chunks are returned as soon as they are generated, significantly reducing the latency (as measured by time to first audio) for large requests. <br> \n",
    "Let's take a look at an example showing batch mode TTS API usage:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a gRPC request to the Riva Speech API server\n",
    "\n",
    "Now let us make a gRPC request to the Riva Speech servers, for TTS, in batch inference mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate_hz = 44100\n",
    "resp = riva_tts.synthesize(\n",
    "    text = \"Is it recognize speech or wreck a nice beach?\",\n",
    "    language_code = \"en-US\",\n",
    "    encoding = riva.client.AudioEncoding.LINEAR_PCM,    # Currently only LINEAR_PCM is supported\n",
    "    sample_rate_hz = sample_rate_hz,                    # Generate 44.1KHz audio\n",
    "    voice_name = \"English-US-Female-1\"         # The name of the voice to generate\n",
    ")\n",
    "\n",
    "audio_samples = np.frombuffer(resp.audio, dtype=np.int16)\n",
    "ipd.Audio(audio_samples, rate=sample_rate_hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding TTS API parameters\n",
    "\n",
    "Riva TTS supports a number of options while making a text-to-speech request to the gRPC endpoint, as shown above. Let's learn more about these parameters:\n",
    "- ``language_code`` - Language of the generated audio. ``\"en-US\"`` represents English (US) and is currently the only language supported OOTB.\n",
    "- ``encoding`` - Type of audio encoding to generate (``LINEAR_PCM``, ``FLAC``, ``MULAW`` and ``ALAW``).\n",
    "- ``sample_rate_hz`` - Sample rate of the generated audio. Depends on the microphone and is usually ``22khz`` or ``44khz``.\n",
    "- ``voice_name`` - Voice used to synthesize the audio. Currently, Riva offers two OOTB voices (``English-US-Female-1``, ``English-US-Male-1``)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we come to an end for the introduction to Riva's offline python client for TTS. Feel free to read more about the Riva's TTS proto [here](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/reference/protos/riva_tts.proto.html?highlight=proto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
